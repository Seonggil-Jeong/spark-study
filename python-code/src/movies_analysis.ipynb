{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:21:51.435643Z",
     "start_time": "2023-08-16T20:21:50.787598Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/17 05:27:27 WARN Utils: Your hostname, SeongGils-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.219.132 instead (on interface en0)\n",
      "23/08/17 05:27:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/17 05:27:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/17 05:27:30 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MoviesAnalysis\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:27:56.576075Z",
     "start_time": "2023-08-16T20:27:24.654873Z"
    }
   },
   "id": "5291bca0e5069330"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4c766dc962897272"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movie_data = spark \\\n",
    "    .read \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"hdfs://localhost:9000/data/movies/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:31:02.360684Z",
     "start_time": "2023-08-16T20:30:59.319330Z"
    }
   },
   "id": "17529857d8e49c39"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Row(SN=1, MOVIE_NM='분노의 질주: 더 얼티메이트', MNG_NM='저스틴 린', MAKR_NM=None, IMPORT_CMPNY_NM='유니버설픽쳐스인터내셔널 코리아(유)', DISTB_CMPNY_NM='유니버설픽쳐스인터내셔널 코리아(유)', OPEN_DE=20210519, MOVIE_TY_NM='개봉영화', MOVIE_STLE_NM='장편', NLTY_NM='미국', WNTY_SCREEN_CO=2296, WNTY_SELNG_AM=17268076580, WNTY_AUDE_CO=1790155, SU_SELNG_AM=4197011990, SU_AUDE_CO=423112, GENRE_NM='액션', GRAD_NM='12세이상관람가', MOVIE_SE='일반영화')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:31:38.428041Z",
     "start_time": "2023-08-16T20:31:37.630796Z"
    }
   },
   "id": "15a58eeb139308e1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "### 함수를 통한 실행계획과 SQL의 실행 계획 차이 비교\n",
    "\n",
    "# csv -> View\n",
    "movie_data.createOrReplaceTempView(\"movie_data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:33:42.167597Z",
     "start_time": "2023-08-16T20:33:42.141082Z"
    }
   },
   "id": "214a208c52f6ed78"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[NLTY_NM#79], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(NLTY_NM#79, 200), ENSURE_REQUIREMENTS, [plan_id=125]\n",
      "      +- HashAggregate(keys=[NLTY_NM#79], functions=[partial_count(1)])\n",
      "         +- FileScan csv [NLTY_NM#79] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/data/movies/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<NLTY_NM:string>\n"
     ]
    }
   ],
   "source": [
    "# 함수를 통한 호출 실행계획\n",
    "movie_data.groupBy(\"NLTY_NM\") \\\n",
    "    .count() \\\n",
    "    .explain()\n",
    "\n",
    "## daptiveSparkPlan isFinalPlan=false:\n",
    "# 이 부분은 적응형 실행 계획의 시작\n",
    "# 적응형 실행 계획은 실행 중에 최적의 처리 경로를 선택할 수 있는 기능을 제공합니다. isFinalPlan=false는 이 계획이 아직 최종적인 것이 아니라는 것\n",
    "\n",
    "## HashAggregate(keys=[NLTY_NM#79], functions=[count(1)]):\n",
    "# 데이터를 그룹화, 집계 함수를 적용 group by NLTY_NM, count() 중간 결과로 활용\n",
    "\n",
    "## Exchange hashpartitioning(NLTY_NM#79, 200), ENSURE_REQUIREMENTS, [plan_id=86]:\n",
    "# 데이터의 분산처리를 위해 데이터를 교환하는 단계,  'NLTY_NM' 열을 기준으로 해시 파티셔닝을 수행하며, 200개의 파티션으로 데이터를 분산\n",
    "# ENSURE_REQUIREMENTS는 실행 환경의 요구 사항을 충족시키기 위한 추가 작업을 수행\n",
    "\n",
    "## ashAggregate(keys=[NLTY_NM#79], functions=[partial_count(1)]):\n",
    "# 이 단계는 이전 단계에서 분산된 데이터를 다시 그룹화하고 집계 함수를 적용\n",
    "# partial_count(1) 집계 함수를 사용하여 각 그룹 내의 레코드 수를 세는 작업을 수행합니다. 'NLTY_NM' 열을 기준으로 그룹화\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:39:42.057164Z",
     "start_time": "2023-08-16T20:39:41.972787Z"
    }
   },
   "id": "cdc5268d5783cac5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[NLTY_NM#79], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(NLTY_NM#79, 200), ENSURE_REQUIREMENTS, [plan_id=138]\n",
      "      +- HashAggregate(keys=[NLTY_NM#79], functions=[partial_count(1)])\n",
      "         +- FileScan csv [NLTY_NM#79] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/data/movies/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<NLTY_NM:string>\n"
     ]
    }
   ],
   "source": [
    "# Query를 통한 호출 실행계획\n",
    "spark.sql(\"\"\"\n",
    "SELECT NLTY_NM, count(1)\n",
    "from movie_data as t1 group by t1.NLTY_NM \n",
    "\"\"\").explain()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:41:25.891545Z",
     "start_time": "2023-08-16T20:41:25.815973Z"
    }
   },
   "id": "785da1a9c3d9c3b7"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|NLTY_NM|screen_total|\n",
      "+-------+------------+\n",
      "|   미국|       14242|\n",
      "|   한국|       12075|\n",
      "|   일본|        3169|\n",
      "|   영국|        1003|\n",
      "| 헝가리|         691|\n",
      "+-------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "select t1.NLTY_NM,\n",
    "sum(t1.WNTY_SCREEN_CO) as screen_total\n",
    "from movie_data as t1\n",
    "group by t1.NLTY_NM\n",
    "order by screen_total desc\n",
    "limit 5\n",
    "\"\"\"\n",
    "spark.sql(q).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:44:39.144955Z",
     "start_time": "2023-08-16T20:44:37.967766Z"
    }
   },
   "id": "2b779bc9bebfea8d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- TakeOrderedAndProject(limit=5, orderBy=[screen_total#422L DESC NULLS LAST], output=[NLTY_NM#79,screen_total#422L])\n",
      "   +- HashAggregate(keys=[NLTY_NM#79], functions=[sum(WNTY_SCREEN_CO#80)])\n",
      "      +- Exchange hashpartitioning(NLTY_NM#79, 200), ENSURE_REQUIREMENTS, [plan_id=445]\n",
      "         +- HashAggregate(keys=[NLTY_NM#79], functions=[partial_sum(WNTY_SCREEN_CO#80)])\n",
      "            +- FileScan csv [NLTY_NM#79,WNTY_SCREEN_CO#80] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/data/movies/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<NLTY_NM:string,WNTY_SCREEN_CO:int>\n"
     ]
    }
   ],
   "source": [
    "spark.sql(q).explain()\n",
    "\n",
    "### dataframe으로 sql 실행 시 실행 계획\n",
    "# csv -(read)> dataframe -(group by)> dataframe -(sum)> dataframe -(change column name)> dataframe -(sort)> dataframe -(limit)> dataframe -(collect)> Array()  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:47:42.731310Z",
     "start_time": "2023-08-16T20:47:42.663946Z"
    }
   },
   "id": "cc0f73a390a453e5"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark.sql(q).collect())\n",
    "\n",
    "## before show() : 이전까지 트렌스포메이션은 하나 또는 그룹의 데이터 프레임을 반환\n",
    "## after show() : 이후에는 이제까지 나온 Dataframe을 사용하는 언어ㅔ 맞게 array or list로 변환"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:49:45.915834Z",
     "start_time": "2023-08-16T20:49:45.373372Z"
    }
   },
   "id": "601cdf7138eb8295"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "### 타입형/비타입형 API의 개념과 차이점\n",
    "### 스파크가 구조적 API의 데이터 흐름을 해석, 클러스터 실행 방식\n",
    "\n",
    "## 구조적 API에는 비타입형(Dataframe)과 타입형(DataSet)으로 구분\n",
    "## 이 차이는 스키마(data 구성요소)에 명시된 데이터 타입의 일치여부를 언제 확인하는지에 따라 구분됨\n",
    "\n",
    "# Dataset : 컴파일타임에서 데이터 요소와 데이터 타입의 일치 여부를 확인,\n",
    "# 따라서 명시적으로 데이터타입을 선언하는 JVM 기반 언어에서만 사용 가능\n",
    "\n",
    "# Dataframe : Row 타입으로 구성된 Dataset\n",
    "\n",
    "### Row타입이란?\n",
    "# 스파크가 사용하는 \"연산에 최적화된 인메모리 포맷\"의 내부적인 표현방식\n",
    "# Row타입 사용시 가비지 컬렉션과 객체 초기화 부하가 있는 JVM 데이터 타입을 사용하는 대신 자체 데이터\n",
    "# 포맷을 사용하여\n",
    "# 결론적으로 Dataframe 사용시 매우 효율적인 연산이 가능"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T20:58:58.649241Z",
     "start_time": "2023-08-16T20:58:58.645184Z"
    }
   },
   "id": "7d9510f062a20d5d"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "## 구조적 API의 실행 과정\n",
    "# 1. DataFrame/Dataset/SQL을 통해 코드 작성\n",
    "#2. 정상적인 코드라면 스파크(카탈리스트 옵티마이저)가 논리적 실행계획으로 변환\n",
    "# 3. 스파크는 논리적 실행 계획을 물리적 실행 계획으로 변환: 이때, 추가적인 최적화 방법이 있는지 확인\n",
    "# 4. 스파크는 클러스터에서 물리적 실행 계획(RDD 처리)을 실행합니다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:00:25.953593Z",
     "start_time": "2023-08-16T21:00:25.935869Z"
    }
   },
   "id": "eccc01cfac804f5c"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "## 논리적 실행 계획 : 논리적 실행계획 단계에서는 추상적 트랜스포메이션만 표현(드라이버나 익스큐터의 정보는 고려X)\n",
    "\n",
    "\n",
    "# 검증 전 논리적 실행 계획 : 사용자가 작성한 코드를 유효성과 테이블의 컬럼 존재 여부만 판단하여 논리적 실행 계획으로 변환 (컴파일과 같은 내용)\n",
    "# 검증된 논리적 실행 계획 : 카탈로그, 모든 테이블의 저장소 그리고 DataFrame 정보등 실제 데이터를 활용하여 스파크 분석기(analyzer)가 검증한 논리적 실행 계획\n",
    "# 최적화된 논리적 실행 계획 : 검증된 논리적 실행계획을 Catalyst Optimizer가 조건절 푸쉬 다운이나 선택절 구문을 이용해 논리적 실행 계획을 최적화함"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:01:24.544371Z",
     "start_time": "2023-08-16T21:01:24.525040Z"
    }
   },
   "id": "346ceebda6c52818"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "## 물리적 실행 계획 : 논리적 실행 계획을 클러스트 환경에서 실행하는 방법을 정의\n",
    "# 다양한 물리적 계획 중 비용 모델을 이용하여 비교 후 최적의 전략을 클러스터에 전달, 실행"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:10:50.444478Z",
     "start_time": "2023-08-16T21:10:50.434875Z"
    }
   },
   "id": "5325bcc64b2f2544"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "### 구조적 API중 집계연산"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:10:50.882299Z",
     "start_time": "2023-08-16T21:10:50.879678Z"
    }
   },
   "id": "99af904973e087"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"hdfs://localhost:9000/data/movies/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105.csv\", header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:11:33.484801Z",
     "start_time": "2023-08-16T21:11:32.691188Z"
    }
   },
   "id": "3e6eed8b6d67d696"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------+-----------------+-----------------------------------+-----------------------------------+-------------------------------------+--------+-----------+-------------+-------+--------------+-------------+------------+-----------+----------+----------+--------------+-------------+\n",
      "| SN|                        MOVIE_NM|           MNG_NM|                            MAKR_NM|                    IMPORT_CMPNY_NM|                       DISTB_CMPNY_NM| OPEN_DE|MOVIE_TY_NM|MOVIE_STLE_NM|NLTY_NM|WNTY_SCREEN_CO|WNTY_SELNG_AM|WNTY_AUDE_CO|SU_SELNG_AM|SU_AUDE_CO|  GENRE_NM|       GRAD_NM|     MOVIE_SE|\n",
      "+---+--------------------------------+-----------------+-----------------------------------+-----------------------------------+-------------------------------------+--------+-----------+-------------+-------+--------------+-------------+------------+-----------+----------+----------+--------------+-------------+\n",
      "|  1|      분노의 질주: 더 얼티메이트|        저스틴 린|                               null|유니버설픽쳐스인터내셔널 코리아(유)|  유니버설픽쳐스인터내셔널 코리아(유)|20210519|   개봉영화|         장편|   미국|          2296|  17268076580|     1790155| 4197011990|    423112|      액션|12세이상관람가|     일반영화|\n",
      "|  2|                        크루엘라|크레이그 질레스피|                               null|월트디즈니컴퍼니코리아 유한책임회사|  월트디즈니컴퍼니코리아 유한책임회사|20210526|   개봉영화|         장편|   미국|          1184|   3038945310|      330181| 1093877910|    116446|    드라마|12세이상관람가|     일반영화|\n",
      "|  3|              비와 당신의 이야기|           조진모|                     (주)아지트필름|                               null|소니픽쳐스엔터테인먼트코리아주식회...|20210428|   개봉영화|         장편|   한국|           957|   2945572300|      314849|  952021490|    105204|    드라마|    전체관람가|     일반영화|\n",
      "|  4|                       더 스파이|        도미닉 쿡|                               null|                   (유)조이앤시네마|        TCO(주)더콘텐츠온,(주)제이...|20210428|   개봉영화|         장편|   미국|           710|   2329329840|      245413|  820905090|     85381|    스릴러|15세이상관람가|     일반영화|\n",
      "|  5|        크루즈 패밀리: 뉴 에이지|    조엘 크로포드|                               null|유니버설픽쳐스인터내셔널 코리아(유)|  유니버설픽쳐스인터내셔널 코리아(유)|20210505|   개봉영화|         장편|   미국|          1082|   1957213560|      222109|  428052040|     46660|애니메이션|    전체관람가|     일반영화|\n",
      "|  6|  극장판 귀멸의 칼날: 무한열차편|  소토자키 하루오|                               null|            에스엠지홀딩스 주식회사|                     워터홀컴퍼니(주)|20210127|   개봉영화|         장편|   일본|           380|   2044649290|      209972|  449049950|     45398|애니메이션|15세이상관람가|     일반영화|\n",
      "|  7|                          미나리|           정이삭|                               null|                       판씨네마(주)|                         판씨네마(주)|20210303|   개봉영화|         장편|   미국|          1162|   1299467860|      143926|  456133820|     50271|    드라마|12세이상관람가|독립/예술영화|\n",
      "|  8|                        스파이럴| 대런 린 보우즈만|                               null|             (주)올스타엔터테인먼트|               (주)올스타엔터테인먼트|20210512|   개봉영화|         장편| 헝가리|           691|   1278892690|      128928|  385959390|     38500|    스릴러|청소년관람불가|     일반영화|\n",
      "|  9|                     내일의 기억|           서유민|   (주)아이필름코퍼레이션,(주)토...|                               null|    (주)아이필름코퍼레이션,씨제이 ...|20210421|   개봉영화|         장편|   한국|           957|   1232214520|      125712|  246713000|     24829|  미스터리|15세이상관람가|     일반영화|\n",
      "| 10|                      파이프라인|             유하|                       (주)곰픽쳐스|                               null|     메가박스중앙(주)플러스엠,(주)...|20210526|   개봉영화|         장편|   한국|           777|    839827490|       96293|  227396030|     26416|      범죄|15세이상관람가|     일반영화|\n",
      "| 11|        명탐정 코난: 비색의 탄환|    나가오카 치카|                               null|                               null|                     (주)씨제이이엔엠|20210416|   개봉영화|         장편|   일본|           844|    717693410|       76885|  166334430|     17210|애니메이션|12세이상관람가|     일반영화|\n",
      "| 12|극장판 콩순이: 장난감나라 대모험|           이선명|                         (주)모꼬지|                               null|      (주)넥스트엔터테인먼트월드(NEW)|20210505|   개봉영화|         장편|   한국|           690|    653801130|       74592|  112841710|     12539|애니메이션|    전체관람가|     일반영화|\n",
      "| 13|          도라에몽: 스탠바이미 2|      야기 류이치|                               null|                     대원미디어(주)|                     (주)스마일이엔티|20210519|   개봉영화|         장편|   일본|           631|    644299040|       73914|  123503460|     13693|애니메이션|    전체관람가|     일반영화|\n",
      "| 14|         내가 죽기를 바라는 자들|    테일러 쉐리던|                               null|            워너브러더스 코리아(주)|              워너브러더스 코리아(주)|20210505|   개봉영화|         장편|   미국|           669|    511060350|       54949|  138693360|     14877|      범죄|15세이상관람가|     일반영화|\n",
      "| 15|                      노매드랜드|      클로이 자오|                               null|월트디즈니컴퍼니코리아 유한책임회사|  월트디즈니컴퍼니코리아 유한책임회사|20210415|   개봉영화|         장편|   미국|           181|    353578540|       37382|  220131140|     23114|    드라마|12세이상관람가|     일반영화|\n",
      "| 16| 극장판 바다 탐험대 옥토넛 : ...|             null|                               null|  (주)얼리버드픽쳐스,와이드 릴리...|                    주식회사 컨텐츠썬|20210428|   개봉영화|         장편|   영국|           183|    220196200|       26723|   46779500|      5438|애니메이션|    전체관람가|     일반영화|\n",
      "| 17|                 아들의 이름으로|           이정국|                          영화사 혼|                               null|                       (주)엣나인필름|20210512|   개봉영화|         장편|   한국|           423|    202838760|       23431|   67224280|      7528|    드라마|12세이상관람가|독립/예술영화|\n",
      "| 18|             내겐 너무 소중한 너|    이창원,권성모|                     (주)파인스토리|                               null|                       (주)파인스토리|20210512|   개봉영화|         장편|   한국|           449|    199479620|       22342|   44281670|      4765|    드라마|12세이상관람가|독립/예술영화|\n",
      "| 19|                 아이들은 즐겁다|           이지원|                     (주)영화사울림|                               null|     메가박스중앙(주)플러스엠,(주)...|20210505|   개봉영화|         장편|   한국|           445|    155307470|       18163|   48878060|      5986|    드라마|    전체관람가|독립/예술영화|\n",
      "| 20|                            서복|           이용주|(주)씨제이이엔엠,(주)티피에스컴퍼니|                               null|                     (주)씨제이이엔엠|20210415|   개봉영화|         장편|   한국|          1382|    172229430|       17639|   44836940|      4466|    드라마|15세이상관람가|     일반영화|\n",
      "+---+--------------------------------+-----------------+-----------------------------------+-----------------------------------+-------------------------------------+--------+-----------+-------------+-------+--------------+-------------+------------+-----------+----------+----------+--------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:11:36.226042Z",
     "start_time": "2023-08-16T21:11:35.694232Z"
    }
   },
   "id": "d8a8cc1688136344"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|SN COUNT|\n",
      "+--------+\n",
      "|     214|\n",
      "+--------+\n"
     ]
    }
   ],
   "source": [
    "# count : 기존 count는 액션이였지만, 해당 count는 트랜스포메이션\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df.select(count(\"SN\").name(\"SN COUNT\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:13:09.446896Z",
     "start_time": "2023-08-16T21:13:08.825755Z"
    }
   },
   "id": "293cc5bf10a8022c"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|approx_count_distinct(SN)|\n",
      "+-------------------------+\n",
      "|                      245|\n",
      "+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# approx_count_distinct : 정확한 count값이 필요하지 않다면 최대 추정 오류율(maximum estimation error) 설정 후 조회 시 근사한 오차를 가지는 개수를 출력\n",
    "\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "df.select(approx_count_distinct(\"SN\", 0.2)).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:14:46.703771Z",
     "start_time": "2023-08-16T21:14:46.075388Z"
    }
   },
   "id": "5d705606b9047156"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------------+-------------------------+--------------------------+\n",
      "|var_pop(WNTY_SELNG_AM)|var_samp(WNTY_SELNG_AM)|stddev_pop(WNTY_SELNG_AM)|stddev_samp(WNTY_SELNG_AM)|\n",
      "+----------------------+-----------------------+-------------------------+--------------------------+\n",
      "|  1.540661170504616...|   1.547894321539849...|     1.2412337292003534E9|        1.24414401157577E9|\n",
      "+----------------------+-----------------------+-------------------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "## 분산과 표준편차\n",
    "\n",
    "#분산과 표준편차를 구할 수 있는 함수\n",
    "# 분산과 표준편차는 평균 주변에 데이터가 분포된 정도를 측정하는 방법\n",
    "# samp : 표본(sample) / 그중 부분 (전국 고등학생 키)\n",
    "# pop : 모(population) / 진짜 \n",
    "# stddev : 표준편차(standard deviation)\n",
    "# var : 표준분산(standard variance)\n",
    "#모집단 : 진짜 전국의 키\n",
    "# 표본집단 : 서울 100명, 부산 100명, 대구 100명 .... 구마다 100명씩 뽑아본다.\n",
    "\n",
    "from pyspark.sql.functions import var_pop, stddev_pop, var_samp, stddev_samp\n",
    "\n",
    "(df.select(var_pop(\"WNTY_SELNG_AM\"),\n",
    "           var_samp(\"WNTY_SELNG_AM\"),\n",
    "           stddev_pop(\"WNTY_SELNG_AM\"),\n",
    "           stddev_samp(\"WNTY_SELNG_AM\"))\n",
    " .show())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:18:02.786935Z",
     "start_time": "2023-08-16T21:18:02.295930Z"
    }
   },
   "id": "24429ab906c76593"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|WNTY_SELNG_AM|\n",
      "+-------------+\n",
      "|  17268076580|\n",
      "|   3038945310|\n",
      "|   2945572300|\n",
      "|   2329329840|\n",
      "|   1957213560|\n",
      "|   2044649290|\n",
      "|   1299467860|\n",
      "|   1278892690|\n",
      "|   1232214520|\n",
      "|    839827490|\n",
      "|    717693410|\n",
      "|    653801130|\n",
      "|    644299040|\n",
      "|    511060350|\n",
      "|    353578540|\n",
      "|    220196200|\n",
      "|    202838760|\n",
      "|    199479620|\n",
      "|    155307470|\n",
      "|    172229430|\n",
      "+-------------+\n"
     ]
    }
   ],
   "source": [
    "df.select(\"WNTY_SELNG_AM\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:16:31.969842Z",
     "start_time": "2023-08-16T21:16:31.703811Z"
    }
   },
   "id": "8ce249a46843cec6"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------------+\n",
      "|skewness(WNTY_SELNG_AM)|kurtosis(WNTY_SELNG_AM)|\n",
      "+-----------------------+-----------------------+\n",
      "|     12.347888659269193|     164.93203214282292|\n",
      "+-----------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "## skewness(비대칭도,왜도), kurtosis(첨도)\n",
    "\n",
    "# 데이터의 변곡점 측정 방법\n",
    "# 확률변수의 확률분포로 데이터 모델링할 때 필요\n",
    "\n",
    "from pyspark.sql.functions import skewness, kurtosis\n",
    "\n",
    "df.select(skewness(\"WNTY_SELNG_AM\"), kurtosis(\"WNTY_SELNG_AM\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:19:01.056046Z",
     "start_time": "2023-08-16T21:18:59.810777Z"
    }
   },
   "id": "f0bf73d5c3513225"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+---------------------------------------+--------------------------------------+\n",
      "|corr(WNTY_SELNG_AM, WNTY_AUDE_CO)|covar_samp(WNTY_SELNG_AM, WNTY_AUDE_CO)|covar_pop(WNTY_SELNG_AM, WNTY_AUDE_CO)|\n",
      "+---------------------------------+---------------------------------------+--------------------------------------+\n",
      "|               0.9998467030541379|                   1.610468908225247E14|                  1.602943352579334...|\n",
      "+---------------------------------+---------------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "## corr(상관관계)과 covar(공분산)\n",
    "# 두 컬럼값 사잉의 영향도를 비교하는 값\n",
    "# 상관관계는 피어슨 상관계수(-1 < 상관계수 < 1)\n",
    "from pyspark.sql.functions import corr, covar_samp, covar_pop\n",
    "\n",
    "# WNTY_SELNG_AM 매출금액 WNTY_AUDE_CO 관람인원\n",
    "df.select(corr(\"WNTY_SELNG_AM\", \"WNTY_AUDE_CO\"),\n",
    "          covar_samp(\"WNTY_SELNG_AM\", \"WNTY_AUDE_CO\"),\n",
    "          covar_pop(\"WNTY_SELNG_AM\", \"WNTY_AUDE_CO\")\n",
    "          ).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:20:12.191579Z",
     "start_time": "2023-08-16T21:20:11.673682Z"
    }
   },
   "id": "73aab79cd5f38f53"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---+---------+----+\n",
      "| NLTY_NM|WNTY_SCREEN_CO|Max|denseRank|Rank|\n",
      "+--------+--------------+---+---------+----+\n",
      "|    기타|            85| 85|        1|   1|\n",
      "|    기타|            70| 85|        2|   2|\n",
      "|    기타|             7| 85|        3|   3|\n",
      "|    기타|            44| 85|        4|   4|\n",
      "|    기타|           223| 85|        5|   5|\n",
      "|    기타|            14| 85|        6|   6|\n",
      "|노르웨이|            63| 63|        1|   1|\n",
      "|    독일|             7|  7|        1|   1|\n",
      "|    독일|            50|  7|        2|   2|\n",
      "|  러시아|             1|  1|        1|   1|\n",
      "|    미국|           780|780|        1|   1|\n",
      "|    미국|           710|780|        2|   2|\n",
      "|    미국|            71|780|        3|   3|\n",
      "|    미국|            70|780|        4|   4|\n",
      "|    미국|           669|780|        5|   5|\n",
      "|    미국|            53|780|        6|   6|\n",
      "|    미국|           505|780|        7|   7|\n",
      "|    미국|            50|780|        8|   8|\n",
      "|    미국|           387|780|        9|   9|\n",
      "|    미국|            38|780|       10|  10|\n",
      "+--------+--------------+---+---------+----+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, dense_rank, rank, col\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "windowSpec = Window \\\n",
    "    .partitionBy(\"NLTY_NM\") \\\n",
    "    .orderBy(desc(\"WNTY_SCREEN_CO\")) \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "maxWNTY_SCREEN_CO = max(col(\"WNTY_SCREEN_CO\")).over(windowSpec)\n",
    "WNTY_SCREEN_CODenseRank = dense_rank().over(windowSpec)\n",
    "WNTY_SCREEN_CORank = rank().over(windowSpec)\n",
    "\n",
    "df.where(\"NLTY_NM IS NOT NULL\").orderBy(\"NLTY_NM\") \\\n",
    "    .select(col(\"NLTY_NM\"), col(\"WNTY_SCREEN_CO\"), maxWNTY_SCREEN_CO.alias(\"Max\"),\n",
    "            WNTY_SCREEN_CODenseRank.alias(\"denseRank\"), WNTY_SCREEN_CORank.alias(\"Rank\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:20:51.859372Z",
     "start_time": "2023-08-16T21:20:50.195638Z"
    }
   },
   "id": "faf1e10f20c1e0a3"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "## Join\n",
    "\n",
    "person = spark.createDataFrame([\n",
    "    (0, \"Bill Chambers\", 0, [100])\n",
    "    , (1, \"one Tak\", 0, [500, 250, 100])\n",
    "    , (2, \"two Taks\", 0, [250, 100])\n",
    "]).toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "\n",
    "graduate_program = spark.createDataFrame([\n",
    "    (0, \"Masters\", \"School of Information\", \"UC Berkeley\")\n",
    "    , (1, \"Masters\", \"EECS\", \"UC Berkeley\")\n",
    "    , (1, \"Ph.D\", \"EECS\", \"UC Berkeley\")\n",
    "]).toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "\n",
    "spark_status = spark.createDataFrame([\n",
    "    (500, \"Vice President\")\n",
    "    , (250, \"PMC Member\")\n",
    "    , (100, \"Contributor\")\n",
    "]).toDF(\"id\", \"status\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:22:03.842902Z",
     "start_time": "2023-08-16T21:22:03.762825Z"
    }
   },
   "id": "84aabe704d398edc"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+\n",
      "| id|         name|graduate_program|   spark_status|\n",
      "+---+-------------+----------------+---------------+\n",
      "|  0|Bill Chambers|               0|          [100]|\n",
      "|  1|      one Tak|               0|[500, 250, 100]|\n",
      "|  2|     two Taks|               0|     [250, 100]|\n",
      "+---+-------------+----------------+---------------+\n",
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|Masters|                EECS|UC Berkeley|\n",
      "|  1|   Ph.D|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "+---+--------------+\n",
      "| id|        status|\n",
      "+---+--------------+\n",
      "|500|Vice President|\n",
      "|250|    PMC Member|\n",
      "|100|   Contributor|\n",
      "+---+--------------+\n"
     ]
    }
   ],
   "source": [
    "person.show()\n",
    "graduate_program.show()\n",
    "spark_status.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:22:16.895831Z",
     "start_time": "2023-08-16T21:22:15.033702Z"
    }
   },
   "id": "4d5d8391125a3864"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "person.createOrReplaceTempView(\"person\")\n",
    "graduate_program.createOrReplaceTempView(\"graduateProgram\")\n",
    "spark_status.createOrReplaceTempView(\"sparkStatus\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:22:30.589789Z",
     "start_time": "2023-08-16T21:22:30.535574Z"
    }
   },
   "id": "a37d09ea4369d6fc"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|      one Tak|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|     two Taks|               0|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "joinExpression = person[\"graduate_program\"] == graduate_program[\"id\"]\n",
    "\n",
    "person.join(graduate_program, joinExpression).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:23:35.996698Z",
     "start_time": "2023-08-16T21:23:35.285827Z"
    }
   },
   "id": "6fbd24ba63adf930"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|      one Tak|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|     two Taks|               0|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "person.join(graduate_program, person[\"graduate_program\"] == graduate_program[\"id\"]).orderBy(person[\"id\"]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:24:49.033177Z",
     "start_time": "2023-08-16T21:24:48.600719Z"
    }
   },
   "id": "559952a9d90b7441"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  1|      one Tak|               0|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|     two Taks|               0|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  0|Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+---+-------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "person.join(graduate_program, joinExpression, \"left\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:25:18.917632Z",
     "start_time": "2023-08-16T21:25:18.207532Z"
    }
   },
   "id": "ef53f7a74be140f8"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "## 왼쪽 세미조인 : 중복키값 포함 왼쪽 세미 조인 / 왼쪽 데이터셋의 키가 오른쪽 데이터셋에 있는 경우 키가 일치하는 왼쪽 데이터셋만 유지\n",
    "\n",
    "graduate_program.join(person, joinExpression, \"left_semi\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:27:04.409814Z",
     "start_time": "2023-08-16T21:27:03.443541Z"
    }
   },
   "id": "3052461ed21f291a"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "|personId|         name|graduate_program|   spark_status| id|        status|\n",
      "+--------+-------------+----------------+---------------+---+--------------+\n",
      "|       0|Bill Chambers|               0|          [100]|100|   Contributor|\n",
      "|       1|      one Tak|               0|[500, 250, 100]|500|Vice President|\n",
      "|       1|      one Tak|               0|[500, 250, 100]|250|    PMC Member|\n",
      "|       1|      one Tak|               0|[500, 250, 100]|100|   Contributor|\n",
      "|       2|     two Taks|               0|     [250, 100]|250|    PMC Member|\n",
      "|       2|     two Taks|               0|     [250, 100]|100|   Contributor|\n",
      "+--------+-------------+----------------+---------------+---+--------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# bool 형식으로 표현 가능한 모든 조건신은 가능함\n",
    "\n",
    "person.withColumnRenamed(\"id\", \"personId\") \\\n",
    "    .join(spark_status, expr(\"array_contains(spark_status,id)\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:28:15.523952Z",
     "start_time": "2023-08-16T21:28:14.366684Z"
    }
   },
   "id": "6c5b508819802ba1"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+----------------+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status|graduate_program| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+----------------+-------+--------------------+-----------+\n",
      "|  1|      one Tak|               0|[500, 250, 100]|               0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|     two Taks|               0|     [250, 100]|               0|Masters|School of Informa...|UC Berkeley|\n",
      "|  0|Bill Chambers|               0|          [100]|               0|Masters|School of Informa...|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+----------------+-------+--------------------+-----------+\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Reference 'graduate_program' is ambiguous, could be: graduate_program, graduate_program.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [81]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m joinExpr \u001B[38;5;241m=\u001B[39m gradProgramDupe[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraduate_program\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m person[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraduate_program\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      6\u001B[0m person\u001B[38;5;241m.\u001B[39mjoin(gradProgramDupe,joinExpr)\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m----> 7\u001B[0m \u001B[43mperson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgradProgramDupe\u001B[49m\u001B[43m,\u001B[49m\u001B[43mjoinExpr\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgraduate_program\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/Development/bigdata/spark-3.3.2/python/pyspark/sql/dataframe.py:2023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \n\u001B[1;32m   2005\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2021\u001B[0m \u001B[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001B[39;00m\n\u001B[1;32m   2022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/Development/bigdata/spark-3.3.2/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
      "File \u001B[0;32m~/Development/bigdata/spark-3.3.2/python/pyspark/sql/utils.py:196\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    192\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: Reference 'graduate_program' is ambiguous, could be: graduate_program, graduate_program."
     ]
    }
   ],
   "source": [
    "## 중복 컬럼명 처리\n",
    "# join할때 중복된 컬럼명으로 select할시 애매모호한 컬럼명이라고 에러 출력\n",
    "\n",
    "gradProgramDupe = graduate_program.withColumnRenamed(\"id\", \"graduate_program\")\n",
    "\n",
    "joinExpr = gradProgramDupe[\"graduate_program\"] == person[\"graduate_program\"]\n",
    "person.join(gradProgramDupe, joinExpr).show()\n",
    "person.join(gradProgramDupe, joinExpr).select(\"graduate_program\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:28:43.288389Z",
     "start_time": "2023-08-16T21:28:41.516209Z"
    }
   },
   "id": "dc5ba318dac03cd3"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|graduate_program|\n",
      "+----------------+\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "+----------------+\n",
      "+----------------+\n",
      "|graduate_program|\n",
      "+----------------+\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "+----------------+\n",
      "+---+-------------+----------------+---------------+-------+-------+--------------------+-----------+\n",
      "| id|         name|graduate_program|   spark_status|grad_id| degree|          department|     school|\n",
      "+---+-------------+----------------+---------------+-------+-------+--------------------+-----------+\n",
      "|  0|Bill Chambers|               0|          [100]|      0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|      one Tak|               0|[500, 250, 100]|      0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|     two Taks|               0|     [250, 100]|      0|Masters|School of Informa...|UC Berkeley|\n",
      "+---+-------------+----------------+---------------+-------+-------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "#### 해결방법 1. 다른 조인 표현식 사용\n",
    "person.join(gradProgramDupe,\"graduate_program\").select(\"graduate_program\").show()\n",
    "\n",
    "#### 해결방법 2. 조인 후 컬럼 제거\n",
    "person.join(gradProgramDupe,joinExpr).drop(person[\"graduate_program\"]).select(\"graduate_program\").show()\n",
    "\n",
    "#### 해결방법 3. 조인 전 컬럼 변경\n",
    "grad = graduate_program.withColumnRenamed(\"id\",\"grad_id\")\n",
    "grad_joinExpr = person[\"graduate_program\"]==grad[\"grad_id\"]\n",
    "person.join(grad,grad_joinExpr).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-16T21:29:29.210258Z",
     "start_time": "2023-08-16T21:29:24.874106Z"
    }
   },
   "id": "cbd3cf50b585629"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7be3671eb9e248"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
